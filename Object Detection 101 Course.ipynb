{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\"Precision and Recall\"](data/Precision%20and%20Recall.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Yolo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 d:\\FPT\\AI\\Major4\\CPV\\OpenCV\\data\\chilren's.png: 352x640 5 persons, 1 bus, 5 backpacks, 1 handbag, 390.4ms\n",
      "Speed: 5.8ms preprocess, 390.4ms inference, 15.6ms postprocess per image at shape (1, 3, 352, 640)\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "\n",
    "model = YOLO('Yolo-Weights/yolov8l.pt')\n",
    "results = model(\"data/chilren's.png\", show=True)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 d:\\FPT\\AI\\Major4\\CPV\\OpenCV\\data\\chilren's.png: 352x640 5 persons, 1 bus, 5 backpacks, 1 handbag, 392.0ms\n",
      "Speed: 0.0ms preprocess, 392.0ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 640)\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "\n",
    "model = YOLO('Yolo-Weights/yolov8l.pt')\n",
    "results = model(\"data/chilren's.png\", show=True)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 d:\\FPT\\AI\\Major4\\CPV\\OpenCV\\data\\cars.jpg: 384x640 17 cars, 453.8ms\n",
      "Speed: 4.0ms preprocess, 453.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "\n",
    "model = YOLO('Yolo-Weights/yolov8l.pt')\n",
    "results = model(\"data/cars.jpg\", show=True)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 d:\\FPT\\AI\\Major4\\CPV\\OpenCV\\data\\motobike.jpg: 480x640 6 motorcycles, 613.9ms\n",
      "Speed: 6.0ms preprocess, 613.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "\n",
    "model = YOLO('Yolo-Weights/yolov8l.pt')\n",
    "results = model(\"data/motobike.jpg\", show=True)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YOLO with webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 chair, 71.7ms\n",
      "Speed: 3.0ms preprocess, 71.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 104.0ms\n",
      "Speed: 5.0ms preprocess, 104.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 90.3ms\n",
      "Speed: 6.5ms preprocess, 90.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 73.6ms\n",
      "Speed: 9.3ms preprocess, 73.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 76.4ms\n",
      "Speed: 2.3ms preprocess, 76.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 71.5ms\n",
      "Speed: 0.7ms preprocess, 71.5ms inference, 7.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 85.4ms\n",
      "Speed: 4.2ms preprocess, 85.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 78.7ms\n",
      "Speed: 0.0ms preprocess, 78.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 86.9ms\n",
      "Speed: 2.6ms preprocess, 86.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 64.4ms\n",
      "Speed: 2.0ms preprocess, 64.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 50.3ms\n",
      "Speed: 1.0ms preprocess, 50.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 65.6ms\n",
      "Speed: 2.0ms preprocess, 65.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 54.9ms\n",
      "Speed: 3.2ms preprocess, 54.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 59.0ms\n",
      "Speed: 1.5ms preprocess, 59.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 63.6ms\n",
      "Speed: 0.0ms preprocess, 63.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 56.1ms\n",
      "Speed: 0.8ms preprocess, 56.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 59.6ms\n",
      "Speed: 0.0ms preprocess, 59.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 66.8ms\n",
      "Speed: 2.4ms preprocess, 66.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 56.7ms\n",
      "Speed: 0.0ms preprocess, 56.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 59.1ms\n",
      "Speed: 0.0ms preprocess, 59.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 54.1ms\n",
      "Speed: 3.8ms preprocess, 54.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 62.1ms\n",
      "Speed: 0.0ms preprocess, 62.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 57.7ms\n",
      "Speed: 3.2ms preprocess, 57.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 58.0ms\n",
      "Speed: 3.1ms preprocess, 58.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 59.7ms\n",
      "Speed: 0.0ms preprocess, 59.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import cvzone\n",
    "import math\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, 1280)\n",
    "cap.set(4, 720)\n",
    "\n",
    "model = YOLO(\"Yolo-Weights/yolov8n.pt\")\n",
    "\n",
    "classNames = [\"person\", \"bicycle\", \"car\", \"motorcycle\", \"airplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "               \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "               \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\",\n",
    "               \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\",\n",
    "               \"kite\", \"baseball bat\", \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\",\n",
    "               \"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\",\n",
    "               \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\",\n",
    "               \"chair\", \"couch\", \"potted plant\", \"bed\", \"dining table\", \"toilet\", \"tv\", \"laptop\",\n",
    "               \"mouse\", \"remote\", \"keyboard\", \"cell phone\", \"microwave\", \"oven\", \"toaster\", \"sink\",\n",
    "               \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\", \"hair drier\",\n",
    "               \"toothbrush\"]\n",
    "\n",
    "\n",
    "while 1:\n",
    "    _, img = cap.read()\n",
    "    results = model(img, stream=True)\n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "        for box in boxes:\n",
    "\n",
    "            # boungding Box\n",
    "            x1, y1, x2, y2 = box.xyxy[0]\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "            # cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 0), 3)\n",
    "            w, h   = x2-x1, y2 - y1\n",
    "            cvzone.cornerRect(img, (x1, y1, w, h))\n",
    "\n",
    "            #confidence\n",
    "            conf = math.ceil((box.conf[0]*100))/100\n",
    "\n",
    "            # Class name\n",
    "            cls = int(box.cls[0])\n",
    "            cvzone.putTextRect(img, f'{classNames[cls]} {conf}', (max(0,x1), max(35,y1)), scale= 1, thickness=1)\n",
    "            \n",
    "    cv2.imshow(\"Image\", img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 352x640 2 persons, 5 cars, 1 motorcycle, 191.6ms\n",
      "Speed: 12.4ms preprocess, 191.6ms inference, 8.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 2 persons, 5 cars, 1 motorcycle, 169.9ms\n",
      "Speed: 5.1ms preprocess, 169.9ms inference, 6.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 2 persons, 5 cars, 1 motorcycle, 137.6ms\n",
      "Speed: 8.0ms preprocess, 137.6ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 2 persons, 5 cars, 1 motorcycle, 132.2ms\n",
      "Speed: 9.5ms preprocess, 132.2ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 1 person, 5 cars, 1 motorcycle, 116.2ms\n",
      "Speed: 3.5ms preprocess, 116.2ms inference, 5.1ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 1 person, 4 cars, 1 motorcycle, 112.2ms\n",
      "Speed: 3.5ms preprocess, 112.2ms inference, 3.7ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 1 person, 4 cars, 1 motorcycle, 1 bus, 122.9ms\n",
      "Speed: 10.0ms preprocess, 122.9ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 1 person, 5 cars, 1 motorcycle, 120.1ms\n",
      "Speed: 3.2ms preprocess, 120.1ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 1 person, 6 cars, 1 motorcycle, 115.7ms\n",
      "Speed: 10.0ms preprocess, 115.7ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 1 person, 6 cars, 1 motorcycle, 117.9ms\n",
      "Speed: 3.9ms preprocess, 117.9ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 1 person, 6 cars, 1 motorcycle, 114.1ms\n",
      "Speed: 4.0ms preprocess, 114.1ms inference, 6.1ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 2 persons, 7 cars, 1 motorcycle, 123.7ms\n",
      "Speed: 3.5ms preprocess, 123.7ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 1 person, 8 cars, 1 motorcycle, 133.8ms\n",
      "Speed: 0.0ms preprocess, 133.8ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 1 person, 7 cars, 1 motorcycle, 1 truck, 144.2ms\n",
      "Speed: 0.0ms preprocess, 144.2ms inference, 2.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 1 person, 6 cars, 1 motorcycle, 1 truck, 120.2ms\n",
      "Speed: 5.5ms preprocess, 120.2ms inference, 3.2ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 1 person, 3 cars, 1 motorcycle, 2 trucks, 102.5ms\n",
      "Speed: 3.3ms preprocess, 102.5ms inference, 10.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 3 persons, 4 cars, 1 motorcycle, 113.5ms\n",
      "Speed: 10.0ms preprocess, 113.5ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 2 persons, 4 cars, 1 motorcycle, 109.5ms\n",
      "Speed: 10.0ms preprocess, 109.5ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 2 persons, 6 cars, 2 motorcycles, 104.6ms\n",
      "Speed: 10.0ms preprocess, 104.6ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 2 persons, 7 cars, 1 motorcycle, 105.9ms\n",
      "Speed: 5.9ms preprocess, 105.9ms inference, 10.0ms postprocess per image at shape (1, 3, 352, 640)\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import cvzone\n",
    "import math\n",
    "\n",
    "cap = cv2.VideoCapture(\"data/Videos/motorbikes.mp4\")\n",
    "cap.set(3, 1280)\n",
    "cap.set(4, 720)\n",
    "\n",
    "model = YOLO(\"Yolo-Weights/yolov8n.pt\")\n",
    "\n",
    "classNames = [\"person\", \"bicycle\", \"car\", \"motorcycle\", \"airplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "               \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "               \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\",\n",
    "               \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\",\n",
    "               \"kite\", \"baseball bat\", \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\",\n",
    "               \"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\",\n",
    "               \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\",\n",
    "               \"chair\", \"couch\", \"potted plant\", \"bed\", \"dining table\", \"toilet\", \"tv\", \"laptop\",\n",
    "               \"mouse\", \"remote\", \"keyboard\", \"cell phone\", \"microwave\", \"oven\", \"toaster\", \"sink\",\n",
    "               \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\", \"hair drier\",\n",
    "               \"toothbrush\"]\n",
    "\n",
    "\n",
    "while 1:\n",
    "    _, img = cap.read()\n",
    "    results = model(img, stream=True)\n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "        for box in boxes:\n",
    "\n",
    "            # boungding Box\n",
    "            x1, y1, x2, y2 = box.xyxy[0]\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "            # cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 0), 3)\n",
    "            w, h   = x2-x1, y2 - y1\n",
    "            cvzone.cornerRect(img, (x1, y1, w, h))\n",
    "\n",
    "            #confidence\n",
    "            conf = math.ceil((box.conf[0]*100))/100\n",
    "\n",
    "            # Class name\n",
    "            cls = int(box.cls[0])\n",
    "            cvzone.putTextRect(img, f'{classNames[cls]} {conf}', (max(0,x1), max(35,y1)), scale= 1, thickness=1)\n",
    "            \n",
    "    cv2.imshow(\"Image\", img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Car counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import cvzone\n",
    "import math\n",
    "from data.Project_1_Car_Counter.sort import * \n",
    "\n",
    "cap = cv2.VideoCapture(\"data/Videos/cars.mp4\")\n",
    "cap.set(3, 1280)\n",
    "cap.set(4, 720)\n",
    "\n",
    "model = YOLO(\"Yolo-Weights/yolov8n.pt\")\n",
    "\n",
    "classNames = [\"person\", \"bicycle\", \"car\", \"motorcycle\", \"airplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "               \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "               \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\",\n",
    "               \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\",\n",
    "               \"kite\", \"baseball bat\", \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\",\n",
    "               \"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\",\n",
    "               \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\",\n",
    "               \"chair\", \"couch\", \"potted plant\", \"bed\", \"dining table\", \"toilet\", \"tv\", \"laptop\",\n",
    "               \"mouse\", \"remote\", \"keyboard\", \"cell phone\", \"microwave\", \"oven\", \"toaster\", \"sink\",\n",
    "               \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\", \"hair drier\",\n",
    "               \"toothbrush\"]\n",
    "\n",
    "mask = cv2.imread(\"data/Project_1_Car_Counter/mask.png\")\n",
    "\n",
    "# tracking\n",
    "tracker = Sort(max_age=20, min_hits=2,iou_threshold=0.3)\n",
    "\n",
    "limits = [400, 297, 673, 297]\n",
    "totalCount = []\n",
    "\n",
    "while 1:\n",
    "    _, img = cap.read()\n",
    "    imgRegion = cv2.bitwise_and(img, mask)\n",
    "\n",
    "    imgGraphics = cv2.imread(\"data/Project_1_Car_Counter/graphics.png\", cv2.IMREAD_UNCHANGED)\n",
    "    cvzone.overlayPNG(img, imgGraphics, (0,0))\n",
    "\n",
    "    detections = np.empty((0,5))\n",
    "\n",
    "    results = model(imgRegion, stream=True)\n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "        for box in boxes:\n",
    "\n",
    "            # boungding Box\n",
    "            x1, y1, x2, y2 = box.xyxy[0]\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "            # cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 0), 3)\n",
    "            w, h   = x2-x1, y2 - y1\n",
    "\n",
    "            #confidence\n",
    "            conf = math.ceil((box.conf[0]*100))/100\n",
    "\n",
    "            # Class name\n",
    "            cls = int(box.cls[0])\n",
    "\n",
    "            currenClass = classNames[cls]\n",
    "            if (currenClass in [\"car\", \"motorbike\", \"truck\", \"bus\"])\\\n",
    "                and (conf > 0.3):\n",
    "                # cvzone.putTextRect(img, f'{classNames[cls]} {conf}', (max(0,x1), max(35,y1)), \n",
    "                #                scale= 0.6, thickness=1, offset=3)\n",
    "                # cvzone.cornerRect(img, (x1, y1, w, h), l=9, rt= 5)\n",
    "                currenArray = np.array([x1, y1, x2, y2, conf])\n",
    "                detections = np.vstack((detections, currenArray))\n",
    "\n",
    "    resultsTracker = tracker.update(detections)  \n",
    "    cv2.line(img, (limits[0], limits[1]), (limits[2], limits[3]), (0, 0, 255), 5)      \n",
    "\n",
    "    for result in resultsTracker:\n",
    "        x1, y1, x2, y2, id = result\n",
    "        x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "        w, h   = x2-x1, y2 - y1\n",
    "        cvzone.cornerRect(img, (x1, y1, w, h), l=9, rt= 2, colorR=(255,0,255))\n",
    "        cvzone.putTextRect(img, f'{int(id)}', (max(0,x1), max(35,y1)), \n",
    "                               scale= 2, thickness=3, offset=10) \n",
    "        \n",
    "        cx, cy = x1 + w//2, y1+h//2\n",
    "        cv2.circle(img, (cx,cy), 5, (255, 0, 255), cv2.FILLED)\n",
    "\n",
    "        if (limits[0] < cx < limits[2]) and (limits[1] - 15 < cy < limits[1] + 15):\n",
    "            if totalCount.count(id) == 0:\n",
    "                totalCount.append(id)\n",
    "                cv2.line(img, (limits[0], limits[1]), (limits[2], limits[3]), (0, 255, 0), 5)\n",
    "\n",
    "\n",
    "    # cvzone.putTextRect(img, f'Count: {int(len(totalCount))}', (50, 50))       \n",
    "    cv2.putText(img, str(len(totalCount)), (255, 100), cv2.FONT_HERSHEY_PLAIN, 5, (50, 50, 255), 8)\n",
    "    cv2.imshow(\"ImageRegion\", img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.1) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:971: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'cv::imshow'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m      8\u001b[0m     _, frame \u001b[38;5;241m=\u001b[39m cap\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m---> 10\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcount people\u001b[39m\u001b[38;5;124m\"\u001b[39m, frame)\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m&\u001b[39m \u001b[38;5;241m0xFF\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m27\u001b[39m:\n\u001b[0;32m     12\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\ultralytics\\utils\\patches.py:55\u001b[0m, in \u001b[0;36mimshow\u001b[1;34m(winname, mat)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimshow\u001b[39m(winname: \u001b[38;5;28mstr\u001b[39m, mat: np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m     48\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;124;03m    Displays an image in the specified window.\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;124;03m        mat (np.ndarray): Image to be shown.\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 55\u001b[0m     _imshow(winname\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124municode_escape\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mdecode(), mat)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.8.1) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:971: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'cv::imshow'\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from data.Project_1_Car_Counter.sort import * "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
